{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oQJ4YkJT0Yt4"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import regexp_replace, lower, trim, col\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, ClusteringEvaluator\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Initialize Spark Session**"
      ],
      "metadata": {
        "id": "P5Z3ipfw1t5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"SentimentAnalysis\") \\\n",
        "    .config(\"spark.executor.memory\", \"8g\") \\\n",
        "    .config(\"spark.driver.memory\", \"8g\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
        "    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "1pF_VygI0baP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Load and Filter Dataset**"
      ],
      "metadata": {
        "id": "yOxnd7yZ28fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load dataset (replace 'your_dataset.csv' with actual file path)\n",
        "data = spark.read.csv('/content/IMDB Dataset.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "TrGGgR9t0dhH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1CuQ28t3Ac0",
        "outputId": "019e4f50-61cd-4ad6-d7f1-afaa2aa3e066"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|              review|           sentiment|\n",
            "+--------------------+--------------------+\n",
            "|One of the other ...|            positive|\n",
            "|\"A wonderful litt...| not only is it w...|\n",
            "|\"I thought this w...| but spirited you...|\n",
            "|Basically there's...|            negative|\n",
            "|\"Petter Mattei's ...| power and succes...|\n",
            "|\"Probably my all-...| but that only ma...|\n",
            "|I sure would like...|            positive|\n",
            "|This show was an ...|            negative|\n",
            "|Encouraged by the...|            negative|\n",
            "|If you like origi...|            positive|\n",
            "|\"Phil the Alien i...|            negative|\n",
            "|I saw this movie ...|            negative|\n",
            "|\"So im not a big ...| meaning most of ...|\n",
            "|The cast played S...|            negative|\n",
            "|This a fantastic ...|            positive|\n",
            "|Kind of drawn in ...|            negative|\n",
            "|Some films just s...|            positive|\n",
            "|This movie made i...|            negative|\n",
            "|I remember this f...|            positive|\n",
            "|An awful film! It...|            negative|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Instead of data.info(), use the following methods to get information about the DataFrame:\n",
        "\n",
        "# Print the schema:\n",
        "data.printSchema()\n",
        "\n",
        "# Get a summary of the DataFrame (similar to Pandas describe()):\n",
        "data.summary().show()\n",
        "\n",
        "# Check the number of rows:\n",
        "data.count()\n",
        "\n",
        "# Display some data:\n",
        "data.show(5) # Shows the first 5 rows"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "VJOoVfpF4kNV",
        "outputId": "262fc50d-d792-4787-b9ed-a48198fabc5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- review: string (nullable = true)\n",
            " |-- sentiment: string (nullable = true)\n",
            "\n",
            "+-------+--------------------+--------------------+\n",
            "|summary|              review|           sentiment|\n",
            "+-------+--------------------+--------------------+\n",
            "|  count|               30097|               30092|\n",
            "|   mean|                NULL|              1240.0|\n",
            "| stddev|                NULL|   1025.802960751096|\n",
            "|    min|!!!! MILD SPOILER...|   \"\" If you need me|\n",
            "|    25%|                NULL|                 0.0|\n",
            "|    50%|                NULL|              1940.0|\n",
            "|    75%|                NULL|              2000.0|\n",
            "|    max|zero day is based...|you don't just ha...|\n",
            "+-------+--------------------+--------------------+\n",
            "\n",
            "+--------------------+--------------------+\n",
            "|              review|           sentiment|\n",
            "+--------------------+--------------------+\n",
            "|One of the other ...|            positive|\n",
            "|\"A wonderful litt...| not only is it w...|\n",
            "|\"I thought this w...| but spirited you...|\n",
            "|Basically there's...|            negative|\n",
            "|\"Petter Mattei's ...| power and succes...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null or missing values in the sentiment column\n",
        "data = data.filter(data.sentiment.isNotNull())"
      ],
      "metadata": {
        "id": "JJZCbY7l0g0_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJZcQrdc3SCc",
        "outputId": "dfc02dae-718c-43bf-e0ac-0bad75206998"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('review', StringType(), True), StructField('sentiment', StringType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure only valid sentiments are processed (assuming 'positive' and 'negative' are the valid labels)\n",
        "valid_sentiments = ['positive', 'negative']\n",
        "data = data.filter(col('sentiment').isin(valid_sentiments))"
      ],
      "metadata": {
        "id": "Qq-xTmV-0i7A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. Data Preprocessing**"
      ],
      "metadata": {
        "id": "dxS90leg3ffc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = data.withColumn('review', trim(lower(regexp_replace(col('review'), '[^a-zA-Z\\s]', ''))))"
      ],
      "metadata": {
        "id": "GnXljEQX0msW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer(inputCol='review', outputCol='tokens')\n",
        "data = tokenizer.transform(data)"
      ],
      "metadata": {
        "id": "vbDdPOrj0nXS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words\n",
        "stopwords_remover = StopWordsRemover(inputCol='tokens', outputCol='filtered_tokens')\n",
        "data = stopwords_remover.transform(data)"
      ],
      "metadata": {
        "id": "9flWWKVc0pc4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to features using CountVectorizer and TF-IDF\n",
        "vectorizer = CountVectorizer(inputCol='filtered_tokens', outputCol='raw_features', vocabSize=3000)\n",
        "vectorized_model = vectorizer.fit(data)\n",
        "data = vectorized_model.transform(data)"
      ],
      "metadata": {
        "id": "xPi452TZ0sJA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "idf = IDF(inputCol='raw_features', outputCol='features')\n",
        "idf_model = idf.fit(data)\n",
        "data = idf_model.transform(data)"
      ],
      "metadata": {
        "id": "CQb5Tx0K0uuJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reduce feature dimensionality with PCA\n",
        "pca = PCA(k=50, inputCol='features', outputCol='pca_features')\n",
        "pca_model = pca.fit(data)\n",
        "data = pca_model.transform(data)"
      ],
      "metadata": {
        "id": "f-Qpjt3u0wrn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the labels\n",
        "label_indexer = StringIndexer(inputCol='sentiment', outputCol='label')\n",
        "data = label_indexer.fit(data).transform(data)"
      ],
      "metadata": {
        "id": "nQ-f21QU0y58"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and test sets\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "ohA1evzL01Fk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Supervised Learning Models**"
      ],
      "metadata": {
        "id": "ITIzrCe-3zyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.1 Logistic Regression"
      ],
      "metadata": {
        "id": "g-bx-UWH336_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr = LogisticRegression(featuresCol='pca_features', labelCol='label')\n",
        "lr_model = lr.fit(train_data)\n",
        "lr_predictions = lr_model.transform(test_data)"
      ],
      "metadata": {
        "id": "hxn-wmgK03Dz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate Logistic Regression\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
        "lr_accuracy = evaluator.evaluate(lr_predictions)\n",
        "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AgV7ox_05Pp",
        "outputId": "ff163007-ade2-4b21-c119-c577c8ff87d9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.7518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2 Gradient Boosting Trees"
      ],
      "metadata": {
        "id": "W_ZLYZKs3-XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gbt = GBTClassifier(featuresCol='pca_features', labelCol='label', maxIter=10)\n",
        "gbt_model = gbt.fit(train_data)\n",
        "gbt_predictions = gbt_model.transform(test_data)\n",
        "gbt_accuracy = evaluator.evaluate(gbt_predictions)\n",
        "print(f\"Gradient Boosting Trees Accuracy: {gbt_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af4Cj_ET07rU",
        "outputId": "4f573369-abaa-4b48-a66d-4920d14d59ea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Trees Accuracy: 0.7150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.3 Multilayer Perceptron Classifier"
      ],
      "metadata": {
        "id": "PjCpUIpt4CzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "layers = [50, 25, 10, 2]  # Input layer, two hidden layers, output layer\n",
        "mlp = MultilayerPerceptronClassifier(featuresCol='pca_features', labelCol='label', layers=layers, maxIter=100)\n",
        "mlp_model = mlp.fit(train_data)\n",
        "mlp_predictions = mlp_model.transform(test_data)\n",
        "mlp_accuracy = evaluator.evaluate(mlp_predictions)\n",
        "print(f\"Multilayer Perceptron Accuracy: {mlp_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlEnUeDR1AFW",
        "outputId": "d78b3c81-aa57-4729-936a-567d56c60ca7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multilayer Perceptron Accuracy: 0.7174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.4 Linear Support Vector Classifier"
      ],
      "metadata": {
        "id": "RzGTO6r64Gjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "svc = LinearSVC(featuresCol='pca_features', labelCol='label', maxIter=10)\n",
        "svc_model = svc.fit(train_data)\n",
        "svc_predictions = svc_model.transform(test_data)\n",
        "svc_accuracy = evaluator.evaluate(svc_predictions)\n",
        "print(f\"Linear SVC Accuracy: {svc_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef6bo9mm1CpT",
        "outputId": "960e5e2c-9f10-44b7-c835-3bf3e9818751"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear SVC Accuracy: 0.7494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Unsupervised Learning Models**"
      ],
      "metadata": {
        "id": "myEKCSUz4LIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 5.1 K-Means Clustering"
      ],
      "metadata": {
        "id": "bSS0aPav4PZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "kmeans = KMeans(featuresCol='pca_features', k=2, seed=42)\n",
        "kmeans_model = kmeans.fit(data)\n",
        "kmeans_predictions = kmeans_model.transform(data)\n",
        "kmeans_evaluator = ClusteringEvaluator()\n",
        "silhouette_score_kmeans = kmeans_evaluator.evaluate(kmeans_predictions)\n",
        "print(f\"K-Means Silhouette Score: {silhouette_score_kmeans:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYlM1TfX1Ex5",
        "outputId": "06442660-8d9b-4ee1-989a-5dd1b0db52ba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Means Silhouette Score: 0.5864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the labels\n",
        "label_indexer_model = StringIndexer(inputCol='sentiment', outputCol='label2').fit(data)\n",
        "data = label_indexer_model.transform(data)\n",
        "\n",
        "# Retrieve label names\n",
        "labels = label_indexer_model.labels"
      ],
      "metadata": {
        "id": "-vOA5m0K1KUD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "pazZP0Vm4UNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Function to calculate and print evaluation metrics\n",
        "def evaluate_model(predictions, label_col='label', prediction_col='prediction', labels=None):\n",
        "    y_true = predictions.select(label_col).toPandas().to_numpy()\n",
        "    y_pred = predictions.select(prediction_col).toPandas().to_numpy()\n",
        "    print(classification_report(y_true, y_pred, target_names=labels))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "id": "mrGsNQvg1KzW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Evaluation\n",
        "print(\"\\nLogistic Regression Metrics:\")\n",
        "evaluate_model(lr_predictions, label_col='label', prediction_col='prediction', labels=labels)\n",
        "\n",
        "# Gradient Boosting Trees Evaluation\n",
        "print(\"\\nGradient Boosting Trees Metrics:\")\n",
        "evaluate_model(gbt_predictions, label_col='label', prediction_col='prediction', labels=labels)\n",
        "\n",
        "# Multilayer Perceptron Evaluation\n",
        "print(\"\\nMultilayer Perceptron Metrics:\")\n",
        "evaluate_model(mlp_predictions, label_col='label', prediction_col='prediction', labels=labels)\n",
        "\n",
        "# Linear SVC Evaluation\n",
        "print(\"\\nLinear SVC Metrics:\")\n",
        "evaluate_model(svc_predictions, label_col='label', prediction_col='prediction', labels=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtT26GIf1NWU",
        "outputId": "44eac573-7c4e-4d04-9386-ddafef3498fa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.77      0.78      0.78       224\n",
            "    negative       0.73      0.72      0.72       183\n",
            "\n",
            "    accuracy                           0.75       407\n",
            "   macro avg       0.75      0.75      0.75       407\n",
            "weighted avg       0.75      0.75      0.75       407\n",
            "\n",
            "Confusion Matrix:\n",
            "[[175  49]\n",
            " [ 52 131]]\n",
            "\n",
            "Gradient Boosting Trees Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.74      0.75      0.74       224\n",
            "    negative       0.69      0.67      0.68       183\n",
            "\n",
            "    accuracy                           0.71       407\n",
            "   macro avg       0.71      0.71      0.71       407\n",
            "weighted avg       0.71      0.71      0.71       407\n",
            "\n",
            "Confusion Matrix:\n",
            "[[168  56]\n",
            " [ 60 123]]\n",
            "\n",
            "Multilayer Perceptron Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.74      0.75      0.75       224\n",
            "    negative       0.69      0.68      0.68       183\n",
            "\n",
            "    accuracy                           0.72       407\n",
            "   macro avg       0.71      0.71      0.71       407\n",
            "weighted avg       0.72      0.72      0.72       407\n",
            "\n",
            "Confusion Matrix:\n",
            "[[168  56]\n",
            " [ 59 124]]\n",
            "\n",
            "Linear SVC Metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.76      0.80      0.78       224\n",
            "    negative       0.74      0.69      0.71       183\n",
            "\n",
            "    accuracy                           0.75       407\n",
            "   macro avg       0.75      0.74      0.75       407\n",
            "weighted avg       0.75      0.75      0.75       407\n",
            "\n",
            "Confusion Matrix:\n",
            "[[179  45]\n",
            " [ 57 126]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iu5IZgLZ2Pn7"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}